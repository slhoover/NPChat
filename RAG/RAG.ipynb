{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b37167f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in ./anaconda3/lib/python3.11/site-packages (2.1.1)\n",
      "Requirement already satisfied: filelock in ./anaconda3/lib/python3.11/site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in ./anaconda3/lib/python3.11/site-packages (from torch) (4.7.1)\n",
      "Requirement already satisfied: sympy in ./anaconda3/lib/python3.11/site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in ./anaconda3/lib/python3.11/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in ./anaconda3/lib/python3.11/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in ./anaconda3/lib/python3.11/site-packages (from torch) (2023.4.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./anaconda3/lib/python3.11/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./anaconda3/lib/python3.11/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./anaconda3/lib/python3.11/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in ./anaconda3/lib/python3.11/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./anaconda3/lib/python3.11/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./anaconda3/lib/python3.11/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./anaconda3/lib/python3.11/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./anaconda3/lib/python3.11/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./anaconda3/lib/python3.11/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in ./anaconda3/lib/python3.11/site-packages (from torch) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./anaconda3/lib/python3.11/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in ./anaconda3/lib/python3.11/site-packages (from torch) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./anaconda3/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.3.101)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./anaconda3/lib/python3.11/site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./anaconda3/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: sentence_transformers in ./anaconda3/lib/python3.11/site-packages (2.2.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in ./anaconda3/lib/python3.11/site-packages (from sentence_transformers) (4.32.1)\n",
      "Requirement already satisfied: tqdm in ./anaconda3/lib/python3.11/site-packages (from sentence_transformers) (4.65.0)\n",
      "Requirement already satisfied: torch>=1.6.0 in ./anaconda3/lib/python3.11/site-packages (from sentence_transformers) (2.1.1)\n",
      "Requirement already satisfied: torchvision in ./anaconda3/lib/python3.11/site-packages (from sentence_transformers) (0.16.1)\n",
      "Requirement already satisfied: numpy in ./anaconda3/lib/python3.11/site-packages (from sentence_transformers) (1.24.3)\n",
      "Requirement already satisfied: scikit-learn in ./anaconda3/lib/python3.11/site-packages (from sentence_transformers) (1.3.0)\n",
      "Requirement already satisfied: scipy in ./anaconda3/lib/python3.11/site-packages (from sentence_transformers) (1.11.1)\n",
      "Requirement already satisfied: nltk in ./anaconda3/lib/python3.11/site-packages (from sentence_transformers) (3.8.1)\n",
      "Requirement already satisfied: sentencepiece in ./anaconda3/lib/python3.11/site-packages (from sentence_transformers) (0.1.99)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in ./anaconda3/lib/python3.11/site-packages (from sentence_transformers) (0.15.1)\n",
      "Requirement already satisfied: filelock in ./anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.9.0)\n",
      "Requirement already satisfied: fsspec in ./anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2023.4.0)\n",
      "Requirement already satisfied: requests in ./anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2.31.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.7.1)\n",
      "Requirement already satisfied: packaging>=20.9 in ./anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (23.1)\n",
      "Requirement already satisfied: sympy in ./anaconda3/lib/python3.11/site-packages (from torch>=1.6.0->sentence_transformers) (1.11.1)\n",
      "Requirement already satisfied: networkx in ./anaconda3/lib/python3.11/site-packages (from torch>=1.6.0->sentence_transformers) (3.1)\n",
      "Requirement already satisfied: jinja2 in ./anaconda3/lib/python3.11/site-packages (from torch>=1.6.0->sentence_transformers) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./anaconda3/lib/python3.11/site-packages (from torch>=1.6.0->sentence_transformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./anaconda3/lib/python3.11/site-packages (from torch>=1.6.0->sentence_transformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./anaconda3/lib/python3.11/site-packages (from torch>=1.6.0->sentence_transformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in ./anaconda3/lib/python3.11/site-packages (from torch>=1.6.0->sentence_transformers) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./anaconda3/lib/python3.11/site-packages (from torch>=1.6.0->sentence_transformers) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./anaconda3/lib/python3.11/site-packages (from torch>=1.6.0->sentence_transformers) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./anaconda3/lib/python3.11/site-packages (from torch>=1.6.0->sentence_transformers) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./anaconda3/lib/python3.11/site-packages (from torch>=1.6.0->sentence_transformers) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./anaconda3/lib/python3.11/site-packages (from torch>=1.6.0->sentence_transformers) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in ./anaconda3/lib/python3.11/site-packages (from torch>=1.6.0->sentence_transformers) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./anaconda3/lib/python3.11/site-packages (from torch>=1.6.0->sentence_transformers) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in ./anaconda3/lib/python3.11/site-packages (from torch>=1.6.0->sentence_transformers) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./anaconda3/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.6.0->sentence_transformers) (12.3.101)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./anaconda3/lib/python3.11/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2022.7.9)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in ./anaconda3/lib/python3.11/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.13.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in ./anaconda3/lib/python3.11/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.3.2)\n",
      "Requirement already satisfied: click in ./anaconda3/lib/python3.11/site-packages (from nltk->sentence_transformers) (8.0.4)\n",
      "Requirement already satisfied: joblib in ./anaconda3/lib/python3.11/site-packages (from nltk->sentence_transformers) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./anaconda3/lib/python3.11/site-packages (from scikit-learn->sentence_transformers) (2.2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./anaconda3/lib/python3.11/site-packages (from torchvision->sentence_transformers) (9.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./anaconda3/lib/python3.11/site-packages (from jinja2->torch>=1.6.0->sentence_transformers) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./anaconda3/lib/python3.11/site-packages (from sympy->torch>=1.6.0->sentence_transformers) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -qU \\\n",
    "  pinecone-client==2.2.1 \\\n",
    "  ipywidgets==7.0.0\n",
    "\n",
    "!pip install torch\n",
    "!pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "060da34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-20 00:34:38.779639: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-20 00:34:38.830826: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-20 00:34:38.830862: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-20 00:34:38.830897: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-20 00:34:38.840437: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-20 00:34:38.841187: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 00:34:40.004414: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/ec2-user/anaconda3/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Embedding, Input, Dense, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "from transformers import T5Tokenizer, T5Model, T5ForConditionalGeneration, AutoModelForSequenceClassification, AutoModelForSeq2SeqLM\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "import os\n",
    "import nltk\n",
    "from nltk.data import find\n",
    "\n",
    "import transformers\n",
    "\n",
    "import re\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "111063b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('Himabindu/finetuned-t5-dialogstudio-npc')\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained('Himabindu/finetuned-t5-dialogstudio-npc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6739c0dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6.76569045e-02  6.34959936e-02  4.87131327e-02  7.93049857e-02\n",
      "   3.74480784e-02  2.65278551e-03  3.93749513e-02 -7.09847128e-03\n",
      "   5.93614466e-02  3.15369666e-02  6.00980632e-02 -5.29051982e-02\n",
      "   4.06067856e-02 -2.59308331e-02  2.98428163e-02  1.12689391e-03\n",
      "   7.35148415e-02 -5.03817834e-02 -1.22386597e-01  2.37028226e-02\n",
      "   2.97265183e-02  4.24768515e-02  2.56337449e-02  1.99515885e-03\n",
      "  -5.69190681e-02 -2.71597914e-02 -3.29035334e-02  6.60248697e-02\n",
      "   1.19007163e-01 -4.58791070e-02 -7.26214200e-02 -3.25840265e-02\n",
      "   5.23413457e-02  4.50552963e-02  8.25298205e-03  3.67023982e-02\n",
      "  -1.39415618e-02  6.53918907e-02 -2.64272150e-02  2.06396420e-04\n",
      "  -1.36643639e-02 -3.62810567e-02 -1.95044018e-02 -2.89738141e-02\n",
      "   3.94270308e-02 -8.84090886e-02  2.62424489e-03  1.36713963e-02\n",
      "   4.83062752e-02 -3.11566219e-02 -1.17329173e-01 -5.11690639e-02\n",
      "  -8.85288045e-02 -2.18962878e-02  1.42986439e-02  4.44167852e-02\n",
      "  -1.34815518e-02  7.43392259e-02  2.66382582e-02 -1.98762771e-02\n",
      "   1.79191511e-02 -1.06051955e-02 -9.04262885e-02  2.13268939e-02\n",
      "   1.41204879e-01 -6.47173403e-03 -1.40378322e-03 -1.53609542e-02\n",
      "  -8.73572007e-02  7.22174272e-02  2.01403089e-02  4.25587781e-02\n",
      "  -3.49013917e-02  3.19517305e-04 -8.02970976e-02 -3.27472389e-02\n",
      "   2.85268519e-02 -5.13658151e-02  1.09389134e-01  8.19328055e-02\n",
      "  -9.84040126e-02 -9.34095830e-02 -1.51291937e-02  4.51248698e-02\n",
      "   4.94172238e-02 -2.51867995e-02  1.57077406e-02 -1.29290715e-01\n",
      "   5.31890756e-03  4.02341317e-03 -2.34571993e-02 -6.72982633e-02\n",
      "   2.92280018e-02 -2.60845236e-02  1.30624948e-02 -3.11663039e-02\n",
      "  -4.82713617e-02 -5.58859184e-02 -3.87504920e-02  1.20010890e-01\n",
      "  -1.03924228e-02  4.89705056e-02  5.53537570e-02  4.49358039e-02\n",
      "  -4.00975440e-03 -1.02959745e-01 -2.92968582e-02 -5.83402663e-02\n",
      "   2.70472337e-02 -2.20168978e-02 -7.22241104e-02 -4.13870066e-02\n",
      "  -1.93297602e-02  2.73332605e-03  2.76950246e-04 -9.67588648e-02\n",
      "  -1.00574709e-01 -1.41922710e-02 -8.07891861e-02  4.53925580e-02\n",
      "   2.45041177e-02  5.97614348e-02 -7.38185048e-02  1.19843911e-02\n",
      "  -6.63403496e-02 -7.69044906e-02  3.85158136e-02 -5.59362183e-33\n",
      "   2.80013848e-02 -5.60784936e-02 -4.86601479e-02  2.15569083e-02\n",
      "   6.01981021e-02 -4.81402762e-02 -3.50247286e-02  1.93314180e-02\n",
      "  -1.75151844e-02 -3.89210396e-02 -3.81060713e-03 -1.70287639e-02\n",
      "   2.82100160e-02  1.28291007e-02  4.71601188e-02  6.21030182e-02\n",
      "  -6.43589497e-02  1.29285589e-01 -1.31231314e-02  5.23069501e-02\n",
      "  -3.73680741e-02  2.89094467e-02 -1.68981198e-02 -2.37330534e-02\n",
      "  -3.33491936e-02 -5.16762510e-02  1.55356592e-02  2.08802987e-02\n",
      "  -1.25371721e-02  4.59578782e-02  3.72719951e-02  2.80567147e-02\n",
      "  -5.90004958e-02 -1.16987843e-02  4.92182635e-02  4.70329113e-02\n",
      "   7.35487565e-02 -3.70530039e-02  3.98457749e-03  1.06412033e-02\n",
      "  -1.61493474e-04 -5.27166240e-02  2.75927987e-02 -3.92921455e-02\n",
      "   8.44717324e-02  4.86860462e-02 -4.85876063e-03  1.79948583e-02\n",
      "  -4.28569727e-02  1.23375300e-02  6.39954628e-03  4.04823087e-02\n",
      "   1.48886926e-02 -1.53940953e-02  7.62948096e-02  2.37043798e-02\n",
      "   4.45237122e-02  5.08195832e-02 -2.31254799e-03 -1.88736934e-02\n",
      "  -1.23335849e-02  4.66001667e-02 -5.63438013e-02  6.29927814e-02\n",
      "  -3.15534920e-02  3.24911997e-02  2.34673228e-02 -6.55438602e-02\n",
      "   2.01709270e-02  2.57082395e-02 -1.23869041e-02 -8.36490560e-03\n",
      "  -6.64377809e-02  9.43073258e-02 -3.57093140e-02 -3.42483260e-02\n",
      "  -6.66361302e-03 -8.01528245e-03 -3.09711043e-02  4.33012284e-02\n",
      "  -8.21402483e-03 -1.50795043e-01  3.07691637e-02  4.00719419e-02\n",
      "  -3.79293263e-02  1.93213753e-03  4.00530547e-02 -8.77075121e-02\n",
      "  -3.68491076e-02  8.57959501e-03 -3.19251716e-02 -1.25258127e-02\n",
      "   7.35539868e-02  1.34734169e-03  2.05918644e-02  2.71098183e-33\n",
      "  -5.18576801e-02  5.78360930e-02 -9.18985009e-02  3.94421630e-02\n",
      "   1.05576500e-01 -1.96911842e-02  6.18402101e-02 -7.63465539e-02\n",
      "   2.40880642e-02  9.40048695e-02 -1.16535448e-01  3.71198319e-02\n",
      "   5.22425137e-02 -3.95856425e-03  5.72214276e-02  5.32850949e-03\n",
      "   1.24016911e-01  1.39022777e-02 -1.10249864e-02  3.56052816e-02\n",
      "  -3.30754519e-02  8.16573873e-02 -1.52003551e-02  6.05585128e-02\n",
      "  -6.01397529e-02  3.26102376e-02 -3.48296762e-02 -1.69881675e-02\n",
      "  -9.74907130e-02 -2.71484070e-02  1.74710900e-03 -7.68982172e-02\n",
      "  -4.31858189e-02 -1.89984869e-02 -2.91660987e-02  5.77488840e-02\n",
      "   2.41821613e-02 -1.16902413e-02 -6.21435083e-02  2.84351334e-02\n",
      "  -2.37563450e-04 -2.51783598e-02  4.39638877e-03  8.12839791e-02\n",
      "   3.64184119e-02 -6.04006723e-02 -3.65517549e-02 -7.93748423e-02\n",
      "  -5.08526620e-03  6.69698939e-02 -1.17784344e-01  3.23743448e-02\n",
      "  -4.71252464e-02 -1.34459510e-02 -9.48445126e-02  8.24950449e-03\n",
      "  -1.06748790e-02 -6.81881458e-02  1.11818197e-03  2.48020180e-02\n",
      "  -6.35889024e-02  2.84492858e-02 -2.61303689e-02  8.58111456e-02\n",
      "   1.14682220e-01 -5.35345711e-02 -5.63588850e-02  4.26009297e-02\n",
      "   1.09454542e-02  2.09579710e-02  1.00131147e-01  3.26050669e-02\n",
      "  -1.84208795e-01 -3.93208228e-02 -6.91454932e-02 -6.38104752e-02\n",
      "  -6.56385869e-02 -6.41252799e-03 -4.79613058e-02 -7.68133178e-02\n",
      "   2.95384899e-02 -2.29948591e-02  4.17037010e-02 -2.50047706e-02\n",
      "  -4.54510888e-03 -4.17136587e-02 -1.32289864e-02 -6.38357401e-02\n",
      "  -2.46472144e-03 -1.37337791e-02  1.68976542e-02 -6.30397946e-02\n",
      "   8.98880810e-02  4.18171175e-02 -1.85687467e-02 -1.80442168e-08\n",
      "  -1.67998075e-02 -3.21577415e-02  6.30383864e-02 -4.13091816e-02\n",
      "   4.44819070e-02  2.02464312e-03  6.29592612e-02 -5.17370133e-03\n",
      "  -1.00444444e-02 -3.05639766e-02  3.52672786e-02  5.58581725e-02\n",
      "  -4.67124544e-02  3.45103070e-02  3.29577960e-02  4.30114977e-02\n",
      "   2.94360984e-02 -3.03164311e-02 -1.71107855e-02  7.37484619e-02\n",
      "  -5.47910072e-02  2.77515128e-02  6.20167702e-03  1.58800241e-02\n",
      "   3.42978761e-02 -5.15751075e-03  2.35080216e-02  7.53135756e-02\n",
      "   1.92842986e-02  3.36197168e-02  5.09103797e-02  1.52497068e-01\n",
      "   1.64208114e-02  2.70528402e-02  3.75162214e-02  2.18553226e-02\n",
      "   5.66333532e-02 -3.95746492e-02  7.12313280e-02 -5.41377105e-02\n",
      "   1.03767426e-03  2.11853478e-02 -3.56309526e-02  1.09016903e-01\n",
      "   2.76535377e-03  3.13997604e-02  1.38415641e-03 -3.45738940e-02\n",
      "  -4.59278077e-02  2.88083311e-02  7.16902735e-03  4.84685265e-02\n",
      "   2.61018500e-02 -9.44066979e-03  2.82169003e-02  3.48724388e-02\n",
      "   3.69099006e-02 -8.58947542e-03 -3.53205651e-02 -2.47856788e-02\n",
      "  -1.91921219e-02  3.80707681e-02  5.99653386e-02 -4.22287509e-02]\n",
      " [ 8.64385962e-02  1.02762654e-01  5.39456215e-03  2.04444095e-03\n",
      "  -9.96334106e-03  2.53855493e-02  4.92875166e-02 -3.06265652e-02\n",
      "   6.87254816e-02  1.01365801e-02  7.75397941e-02 -9.00807008e-02\n",
      "   6.10618247e-03 -5.69898635e-02  1.41714690e-02  2.80491672e-02\n",
      "  -8.68464932e-02  7.64399096e-02 -1.03491336e-01 -6.77438006e-02\n",
      "   6.99946657e-02  8.44250992e-02 -7.24912342e-03  1.04770605e-02\n",
      "   1.34020662e-02  6.77577108e-02 -9.42086205e-02 -3.71689834e-02\n",
      "   5.22617251e-02 -3.10853180e-02 -9.63406861e-02  1.57716721e-02\n",
      "   2.57866867e-02  7.85245150e-02  7.89948925e-02  1.91515945e-02\n",
      "   1.64356362e-02  3.10088531e-03  3.81311253e-02  2.37090867e-02\n",
      "   1.05389664e-02 -4.40644994e-02  4.41738591e-02 -2.58728154e-02\n",
      "   6.15378916e-02 -4.05427851e-02 -8.64140093e-02  3.19722481e-02\n",
      "  -8.90617317e-04 -2.44437121e-02 -9.19720978e-02  2.33939271e-02\n",
      "  -8.30293596e-02  4.41510864e-02 -2.49693003e-02  6.23019934e-02\n",
      "  -1.30349759e-03  7.51395375e-02  2.46384870e-02 -6.47244602e-02\n",
      "  -1.17727757e-01  3.83392163e-02 -9.11767334e-02  6.35446087e-02\n",
      "   7.62739852e-02 -8.80241245e-02  9.54557396e-03 -4.69717905e-02\n",
      "  -8.41740593e-02  3.88823636e-02 -1.14393570e-01  6.28859550e-03\n",
      "  -3.49361785e-02  2.39749979e-02 -3.31316814e-02 -1.57243852e-02\n",
      "  -3.78955863e-02 -8.81253462e-03  7.06118867e-02  3.28066424e-02\n",
      "   2.03669630e-03 -1.12278983e-01  6.79723127e-03  1.22765526e-02\n",
      "   3.35303657e-02 -1.36200711e-02 -2.25490071e-02 -2.25228611e-02\n",
      "  -2.03195233e-02  5.04297502e-02 -7.48652741e-02 -8.22822452e-02\n",
      "   7.65962675e-02  4.93392125e-02 -3.75553630e-02  1.44634712e-02\n",
      "  -5.72457984e-02 -1.79954432e-02  1.09697968e-01  1.19462766e-01\n",
      "   8.09228863e-04  6.17057234e-02  3.26322354e-02 -1.30780071e-01\n",
      "  -1.48636654e-01 -6.16232753e-02  4.33886126e-02  2.67129187e-02\n",
      "   1.39786135e-02 -3.94002497e-02 -2.52711978e-02  3.87741136e-03\n",
      "   3.58664505e-02 -6.15420118e-02  3.76660489e-02  2.67565064e-02\n",
      "  -3.82658988e-02 -3.54793258e-02 -2.39227209e-02  8.67977291e-02\n",
      "  -1.84062831e-02  7.71039352e-02  1.39867340e-03  7.00383037e-02\n",
      "  -4.77878004e-02 -7.89819881e-02  5.10814749e-02 -2.99868444e-33\n",
      "  -3.91646139e-02 -2.56210356e-03  1.65210459e-02  9.48938727e-03\n",
      "  -5.66219315e-02  6.57783002e-02 -4.77002710e-02  1.11662298e-02\n",
      "  -5.73558062e-02 -9.16259829e-03 -2.17521302e-02 -5.59531935e-02\n",
      "  -1.11422734e-02  9.32793096e-02  1.66765396e-02 -1.36723574e-02\n",
      "   4.34388667e-02  1.87244685e-03  7.29949540e-03  5.16332276e-02\n",
      "   4.80608344e-02  1.35341436e-01 -1.71738863e-02 -1.29698385e-02\n",
      "  -7.50109628e-02  2.61107795e-02  2.69802175e-02  7.83052179e-04\n",
      "  -4.87270169e-02  1.17842555e-02 -4.59580310e-02 -4.83213216e-02\n",
      "  -1.95671245e-02  1.93889178e-02  1.98807567e-02  1.67432316e-02\n",
      "   9.87801179e-02 -2.74087619e-02  2.34809145e-02  3.70226311e-03\n",
      "  -6.14514612e-02 -1.21230073e-03 -9.50472429e-03  9.25153773e-03\n",
      "   2.38443948e-02  8.61232057e-02  2.26790030e-02  5.45131683e-04\n",
      "   3.47129554e-02  6.25464832e-03 -6.92775799e-03  3.92400324e-02\n",
      "   1.15674697e-02  3.26279849e-02  6.22155629e-02  2.76114717e-02\n",
      "   1.86883323e-02  3.55805829e-02  4.11795974e-02  1.54782180e-02\n",
      "   4.22691628e-02  3.82248461e-02  1.00313518e-02 -2.83245910e-02\n",
      "   4.47052568e-02 -4.10458520e-02 -4.50548902e-03 -5.44734113e-02\n",
      "   2.62320917e-02  1.79862492e-02 -1.23118766e-01 -4.66952063e-02\n",
      "  -1.35913016e-02  6.46710396e-02  3.57346213e-03 -1.22233909e-02\n",
      "  -1.79382153e-02 -2.55502146e-02  2.37223953e-02  4.08667838e-03\n",
      "  -6.51476011e-02  4.43651527e-02  4.68596108e-02 -3.25174667e-02\n",
      "   4.02267557e-03 -3.97605263e-03  1.11939730e-02 -9.95597690e-02\n",
      "   3.33168618e-02  8.01060572e-02  9.42692384e-02 -6.38294220e-02\n",
      "   3.23151834e-02 -5.13553433e-02 -7.49875838e-03  5.30049459e-34\n",
      "  -4.13195007e-02  9.49646831e-02 -1.06401421e-01  4.96590249e-02\n",
      "  -3.41913030e-02 -3.16745900e-02 -1.71556138e-02  1.70102995e-03\n",
      "   5.79757690e-02 -1.21774722e-03 -1.68536324e-02 -5.16912639e-02\n",
      "   5.52998893e-02 -3.42647471e-02  3.08179259e-02 -3.10480446e-02\n",
      "   9.27532688e-02  3.72663885e-02 -2.37398427e-02  4.45893593e-02\n",
      "   1.46153327e-02  1.16239354e-01 -5.00112623e-02  3.88716497e-02\n",
      "   4.24743816e-03  2.56976411e-02  3.27243991e-02  4.29907143e-02\n",
      "  -1.36144627e-02  2.56122444e-02  1.06262583e-02 -8.46864060e-02\n",
      "  -9.52982083e-02  1.08399853e-01 -7.51600266e-02 -1.37773613e-02\n",
      "   6.37338236e-02 -4.49669641e-03 -3.25321406e-02  6.23614043e-02\n",
      "   3.48053239e-02 -3.54922451e-02 -2.00222656e-02  3.66608463e-02\n",
      "  -2.48837229e-02  1.01818610e-02 -7.01233447e-02 -4.31950800e-02\n",
      "   2.95332391e-02 -2.94912257e-04 -3.45386975e-02  1.46675976e-02\n",
      "  -9.83970240e-02 -4.70488258e-02 -8.85496102e-03 -8.89913812e-02\n",
      "   3.50995995e-02 -1.29601985e-01 -4.98866104e-02 -6.12047538e-02\n",
      "  -5.97797409e-02  9.46320780e-03  4.91217934e-02 -7.75026679e-02\n",
      "   8.09727088e-02 -4.79257219e-02  2.34377990e-03  7.57031515e-02\n",
      "  -2.40175743e-02 -1.52546261e-02  4.86738496e-02 -3.85968462e-02\n",
      "  -7.04831406e-02 -1.20348521e-02 -3.88790593e-02 -7.76017383e-02\n",
      "  -1.07243881e-02  1.04187969e-02 -2.13753991e-02 -9.17386115e-02\n",
      "  -1.11344801e-02 -2.96066012e-02  2.46458370e-02  4.65711579e-03\n",
      "  -1.63449924e-02 -3.95219699e-02  7.73373768e-02 -2.84732711e-02\n",
      "  -3.69937904e-03  8.27665105e-02 -1.10409027e-02  3.13983336e-02\n",
      "   5.35094514e-02  5.75145744e-02 -3.17622237e-02 -1.52911248e-08\n",
      "  -7.99661577e-02 -4.76796702e-02 -8.59788582e-02  5.69616482e-02\n",
      "  -4.08866666e-02  2.23832466e-02 -4.64448240e-03 -3.80130559e-02\n",
      "  -3.10670994e-02 -1.07278004e-02  1.97698697e-02  7.77001493e-03\n",
      "  -6.09473046e-03 -3.86376083e-02  2.80271824e-02  6.78137839e-02\n",
      "  -2.35351380e-02  3.21747474e-02  8.02538078e-03 -2.39107162e-02\n",
      "  -1.21997728e-03  3.14599127e-02 -5.24924174e-02 -8.06814712e-03\n",
      "   3.14774737e-03  5.11496402e-02 -4.44104336e-02  6.36013150e-02\n",
      "   3.85083966e-02  3.30432989e-02 -4.18726588e-03  4.95592766e-02\n",
      "  -5.69605231e-02 -6.49712933e-03 -2.49793082e-02 -1.60867367e-02\n",
      "   6.62289709e-02 -2.06310730e-02  1.08045734e-01  1.68547183e-02\n",
      "   1.43812485e-02 -1.32127488e-02 -1.29387408e-01  6.95216656e-02\n",
      "  -5.55772893e-02 -6.75413311e-02 -5.45822829e-03 -6.13594009e-03\n",
      "   3.90840657e-02 -6.28779382e-02  3.74063253e-02 -1.16570620e-02\n",
      "   1.29150087e-02 -5.52495420e-02  5.16076013e-02 -4.30837553e-03\n",
      "   5.80247901e-02  1.86944678e-02  2.27810293e-02  3.21665257e-02\n",
      "   5.37978895e-02  7.02849030e-02  7.49312192e-02 -8.41775090e-02]]\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "sentences = [\"This is an example sentence\", \"Each sentence is converted\"]\n",
    "\n",
    "encoder = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "embeddings = encoder.encode(sentences)\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45c2c524",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading tokenizer_config.json: 100%|███████████████████████████████████████████████████████████████████████████| 350/350 [00:00<00:00, 1.91MB/s]\n",
      "Downloading vocab.txt: 100%|█████████████████████████████████████████████████████████████████████████████████████| 232k/232k [00:00<00:00, 67.8MB/s]\n",
      "Downloading tokenizer.json: 100%|████████████████████████████████████████████████████████████████████████████████| 466k/466k [00:00<00:00, 69.0MB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████████████████████████████████████████████████████████████████████| 112/112 [00:00<00:00, 779kB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 2070, 3793, 2182, 102, 0, 0, 0], [101, 2070, 2062, 3793, 3632, 2182, 2205, 102]]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "mini_lm_tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")\n",
    "\n",
    "# create token IDs for both sequences\n",
    "token_ids = mini_lm_tokenizer(\n",
    "    [\"some text here\", \"some more text goes here too\"],\n",
    "    padding=True,\n",
    "    return_attention_mask=False,\n",
    "    return_token_type_ids=False\n",
    ")\n",
    "token_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5317b289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'some', 'text', 'here', '[SEP]', '[PAD]', '[PAD]', '[PAD]']\n",
      "['[CLS]', 'some', 'more', 'text', 'goes', 'here', 'too', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "# convert these token IDs into plain text tokens\n",
    "for token_ids_list in token_ids[\"input_ids\"]:\n",
    "    print(mini_lm_tokenizer.convert_ids_to_tokens(token_ids_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "84905a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import numpy as np\n",
    "\n",
    "def embed_docs(docs: List[str]) -> List[List[float]]:\n",
    "    out = encoder.encode(docs)\n",
    "    return out.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51590677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: pinecone-client in ./anaconda3/lib/python3.11/site-packages (2.2.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in ./anaconda3/lib/python3.11/site-packages (from pinecone-client) (2.31.0)\n",
      "Requirement already satisfied: pyyaml>=5.4 in ./anaconda3/lib/python3.11/site-packages (from pinecone-client) (6.0)\n",
      "Requirement already satisfied: loguru>=0.5.0 in ./anaconda3/lib/python3.11/site-packages (from pinecone-client) (0.7.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in ./anaconda3/lib/python3.11/site-packages (from pinecone-client) (4.7.1)\n",
      "Requirement already satisfied: dnspython>=2.0.0 in ./anaconda3/lib/python3.11/site-packages (from pinecone-client) (2.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in ./anaconda3/lib/python3.11/site-packages (from pinecone-client) (2.8.2)\n",
      "Requirement already satisfied: urllib3>=1.21.1 in ./anaconda3/lib/python3.11/site-packages (from pinecone-client) (1.26.16)\n",
      "Requirement already satisfied: tqdm>=4.64.1 in ./anaconda3/lib/python3.11/site-packages (from pinecone-client) (4.65.0)\n",
      "Requirement already satisfied: numpy in ./anaconda3/lib/python3.11/site-packages (from pinecone-client) (1.24.3)\n",
      "Requirement already satisfied: six>=1.5 in ./anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.5.3->pinecone-client) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./anaconda3/lib/python3.11/site-packages (from requests>=2.19.0->pinecone-client) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./anaconda3/lib/python3.11/site-packages (from requests>=2.19.0->pinecone-client) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./anaconda3/lib/python3.11/site-packages (from requests>=2.19.0->pinecone-client) (2023.7.22)\n"
     ]
    }
   ],
   "source": [
    "!pip install pinecone-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "331c4a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "042fa510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add Pinecone API key from app.pinecone.io\n",
    "api_key = \"828c0ba7-fbe7-4f81-bd61-5b9c8ae0912a\"\n",
    "# set Pinecone environment - find next to API key in console\n",
    "env = \"gcp-starter\"\n",
    "pinecone.init(\n",
    "    api_key=api_key,\n",
    "    environment=env\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0aa74b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "index_name = 'npc-rag'\n",
    "\n",
    "if index_name in pinecone.list_indexes():\n",
    "    pinecone.delete_index(index_name)\n",
    "    \n",
    "pinecone.create_index(\n",
    "    name=index_name,\n",
    "    dimension=embeddings.shape[1],\n",
    "    metric='cosine'\n",
    ")\n",
    "# wait for index to finish initialization\n",
    "while not pinecone.describe_index(index_name).status['ready']:\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8296014c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/home/ec2-user/.cache/huggingface/datasets/amaydle___parquet/amaydle--npc-dialogue-90a44e1b412a95be/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Found cached dataset parquet (/home/ec2-user/.cache/huggingface/datasets/amaydle___parquet/amaydle--npc-dialogue-90a44e1b412a95be/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "/tmp/ipykernel_4116/3469310117.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  character_level_dataset.drop_duplicates(inplace=True)\n",
      "/tmp/ipykernel_4116/3469310117.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  character_level_dataset['answers'] = character_level_dataset['name'] + ' ' + character_level_dataset['bio']\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "npc_train = load_dataset(\"amaydle/npc-dialogue\", split=\"train\")\n",
    "npc_test = load_dataset(\"amaydle/npc-dialogue\", split=\"test\")\n",
    "\n",
    "# Automatically splits it into train and test for you - let's ignore that for now and just combine them as one\n",
    "\n",
    "# First, transform them into pandas DFs\n",
    "train = pd.DataFrame(data = {'name': npc_train['Name'], 'bio':npc_train['Biography'], 'query':npc_train['Query'], 'response':npc_train['Response'], 'emotion':npc_train['Emotion']})\n",
    "test = pd.DataFrame(data = {'name': npc_test['Name'], 'bio':npc_test['Biography'], 'query':npc_test['Query'], 'response':npc_test['Response'], 'emotion':npc_test['Emotion']})\n",
    "\n",
    "# Now combine into a single df\n",
    "npc = pd.concat([train, test])\n",
    "npc\n",
    "\n",
    "# Create a character-level dataset, since the characters show up multiple times in the dataset\n",
    "character_level_dataset = npc[['name', 'bio']]\n",
    "character_level_dataset.drop_duplicates(inplace=True)\n",
    "character_level_dataset['answers'] = character_level_dataset['name'] + ' ' + character_level_dataset['bio']\n",
    "character_level_dataset = character_level_dataset[['answers']]\n",
    "character_level_dataset = pd.concat([character_level_dataset, pd.DataFrame(data={'answers':['The Magic Key is under the bridge', 'The sword is in the cave']})])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e9b57164",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 52/52 [00:05<00:00, 10.06it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "batch_size = 2  # can increase but needs larger instance size otherwise instance runs out of memory\n",
    "vector_limit = 1000\n",
    "\n",
    "answers = character_level_dataset\n",
    "index = pinecone.Index(index_name)\n",
    "\n",
    "for i in tqdm(range(0, len(answers), batch_size)):\n",
    "    # find end of batch\n",
    "    i_end = min(i+batch_size, len(answers))\n",
    "    # create IDs batch\n",
    "    ids = [str(x) for x in range(i, i_end)]\n",
    "    # create metadata batch\n",
    "    metadatas = [{'text': text} for text in answers[\"answers\"][i:i_end]]\n",
    "    # create embeddings\n",
    "    texts = answers[\"answers\"][i:i_end].tolist()\n",
    "    embeddings = embed_docs(texts)\n",
    "    # create records list for upsert\n",
    "    records = zip(ids, embeddings, metadatas)\n",
    "    # upsert to Pinecone\n",
    "    index.upsert(vectors=records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6e7ec101",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bikram Bikram is a rough and tough smuggler fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arcturus the Bounty Hunter Arcturus is a fearl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Elena Gilbert Elena Gilbert is a teenage girl ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arin the Cleric Arin is a devoted follower of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Scott McCall Scott McCall is a teenage werewol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>Tony Stark Tony Stark, genius inventor and bil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>Thorne Thorne is a mysterious elf who has live...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1493</th>\n",
       "      <td>Lara Croft Lara Croft is a British archaeologi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Magic Key is under the bridge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The sword is in the cave</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>104 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                answers\n",
       "0     Bikram Bikram is a rough and tough smuggler fr...\n",
       "1     Arcturus the Bounty Hunter Arcturus is a fearl...\n",
       "2     Elena Gilbert Elena Gilbert is a teenage girl ...\n",
       "3     Arin the Cleric Arin is a devoted follower of ...\n",
       "4     Scott McCall Scott McCall is a teenage werewol...\n",
       "...                                                 ...\n",
       "634   Tony Stark Tony Stark, genius inventor and bil...\n",
       "646   Thorne Thorne is a mysterious elf who has live...\n",
       "1493  Lara Croft Lara Croft is a British archaeologi...\n",
       "0                     The Magic Key is under the bridge\n",
       "1                              The sword is in the cave\n",
       "\n",
       "[104 rows x 1 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "character_level_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "385f2664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 384,\n",
       " 'index_fullness': 0.00104,\n",
       " 'namespaces': {'': {'vector_count': 104}},\n",
       " 'total_vector_count': 104}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check number of records in the index\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7d9468de",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = [\"What powers does you have?\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "cbc67f07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'matches': [{'id': '16',\n",
       "              'metadata': {'text': 'Elsa Elsa is the Snow Queen of Arendelle, '\n",
       "                                   'with the power to control ice and snow. '\n",
       "                                   'She grew up with her younger sister Anna '\n",
       "                                   'but was forced to hide her powers after an '\n",
       "                                   'accident. In the first game, she comes to '\n",
       "                                   'grips with her powers and learns to '\n",
       "                                   'control them. In the second game, she '\n",
       "                                   'helps save her kingdom and discovers the '\n",
       "                                   'origin of her powers.'},\n",
       "              'score': 0.780111194,\n",
       "              'values': []},\n",
       "             {'id': '21',\n",
       "              'metadata': {'text': 'Kaela the Enchantress Kaela is a powerful '\n",
       "                                   'enchantress who was born with a natural '\n",
       "                                   'affinity for magic. She spent most of her '\n",
       "                                   'childhood in the forests, communing with '\n",
       "                                   'nature and learning how to harness the '\n",
       "                                   'magical energies that flowed through the '\n",
       "                                   'world. As she grew older, she became more '\n",
       "                                   'and more skilled in the art of '\n",
       "                                   'enchantment, and eventually became known '\n",
       "                                   'as one of the most powerful enchantresses '\n",
       "                                   'in the land.'},\n",
       "              'score': 0.394248247,\n",
       "              'values': []},\n",
       "             {'id': '80',\n",
       "              'metadata': {'text': 'Marcella Ravenwood Marcella Ravenwood is a '\n",
       "                                   'powerful sorceress who comes from a long '\n",
       "                                   'line of magic-users. She has been studying '\n",
       "                                   'magic since she was a young girl and has '\n",
       "                                   'honed her skills over the years to become '\n",
       "                                   'one of the most respected practitioners of '\n",
       "                                   'the arcane arts.'},\n",
       "              'score': 0.376277804,\n",
       "              'values': []},\n",
       "             {'id': '59',\n",
       "              'metadata': {'text': 'Lady Hela Lady Hela is the daughter of a '\n",
       "                                   'powerful sorcerer and the ruler of the '\n",
       "                                   'Shadowrealm. She is cunning, ruthless and '\n",
       "                                   'possesses immense magical power. Her goal '\n",
       "                                   'is to conquer the world and establish her '\n",
       "                                   'rule over all realms.'},\n",
       "              'score': 0.375970781,\n",
       "              'values': []},\n",
       "             {'id': '54',\n",
       "              'metadata': {'text': 'Faela Faela is a mischievous elf who grew '\n",
       "                                   'up in the enchanted forests of Elvendom. '\n",
       "                                   'She has a sharp wit and a playful '\n",
       "                                   'personality, but can be quite cunning when '\n",
       "                                   'she wants to be. As a member of the Elven '\n",
       "                                   'Ranger Corps, she has honed her skills in '\n",
       "                                   'archery and tracking, and has a deep '\n",
       "                                   'respect for nature and its inhabitants.'},\n",
       "              'score': 0.359760463,\n",
       "              'values': []}],\n",
       " 'namespace': ''}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract embeddings for the questions\n",
    "query_vec = embed_docs(question)[0]\n",
    "\n",
    "# query pinecone\n",
    "res = index.query(query_vec, top_k=5, include_metadata=True)\n",
    "\n",
    "# show the results\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ca766aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_section_len = 1000\n",
    "separator = \"\\n\"\n",
    "\n",
    "def construct_context(contexts: List[str]) -> str:\n",
    "    chosen_sections = []\n",
    "    chosen_sections_len = 1\n",
    "    \n",
    "    chosen_sections = contexts[:chosen_sections_len]\n",
    "    concatenated_doc = separator.join(chosen_sections)\n",
    "    print(\n",
    "        f\"With maximum sequence length {max_section_len}, selected top {len(chosen_sections)} document sections: \\n{concatenated_doc}\"\n",
    "    )\n",
    "    return concatenated_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5fcb3864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With maximum sequence length 1000, selected top 1 document sections: \n",
      "Elsa Elsa is the Snow Queen of Arendelle, with the power to control ice and snow. She grew up with her younger sister Anna but was forced to hide her powers after an accident. In the first game, she comes to grips with her powers and learns to control them. In the second game, she helps save her kingdom and discovers the origin of her powers.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "context_str = construct_context(contexts=contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4c56058a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<pad> Elsa has the power to control the elements and helps her navigate through difficult situations. '"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_input = context_str + question[0]\n",
    "test_tokenized = tokenizer.encode_plus(text_input, return_tensors=\"pt\")\n",
    "\n",
    "test_input_ids  = test_tokenized[\"input_ids\"]\n",
    "test_attention_mask = test_tokenized[\"attention_mask\"]\n",
    "\n",
    "out = model.generate(\n",
    "  input_ids=test_input_ids,attention_mask=test_attention_mask\n",
    ")\n",
    "\n",
    "tokenizer.decode(out[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ba7b28b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [1289, 7, 9, 1289, 7, 9, 19, 8, 9394, 5286, 13, 1521, 727, 693, 6, 28, 8, 579, 12, 610, 3, 867, 11, 2983, 5, 451, 3, 4774, 95, 28, 160, 5868, 4806, 7588, 68, 47, 5241, 12, 7387, 160, 11552, 227, 46, 3125, 5, 86, 8, 166, 467, 6, 255, 639, 12, 7411, 7, 28, 160, 11552, 11, 669, 7, 12, 610, 135, 5, 86, 8, 511, 467, 6, 255, 1691, 1097, 160, 14740, 11, 2928, 7, 8, 5233, 13, 160, 11552, 5, 5791, 5434, 5634, 4055, 49, 5791, 5434, 19, 3, 9, 985, 18, 10386, 620, 52, 113, 3, 4774, 95, 16, 8, 5827, 28, 160, 3, 15, 40, 1926, 2039, 11, 936, 2353, 5, 451, 65, 3, 9, 19894, 333, 21, 1405, 11, 3, 9, 1659, 2135, 12, 8, 3127, 13, 8, 5827, 5, 5791, 5434, 19, 1704, 18, 7820, 1054, 11, 2547, 6, 68, 54, 36, 26246, 17, 1329, 13, 1067, 52, 7, 788, 12, 160, 95, 3770, 5, 1699, 15, 521, 1699, 15, 521, 19, 3, 9, 1817, 9781, 3249, 3, 10386, 113, 3, 4774, 95, 16, 8, 3, 35, 8694, 1054, 15099, 13, 1289, 1926, 5012, 5, 451, 65, 3, 9, 4816, 3, 7820, 11, 3, 9, 22071, 6794, 6, 68, 54, 36, 882, 123, 9416, 116, 255, 2746, 12, 36, 5, 282, 3, 9, 1144, 13, 8, 1289, 1926, 10971, 52, 16829, 6, 255, 65, 3, 107, 782, 26, 160, 1098, 16, 11508, 4203, 11, 6418, 6, 11, 65, 3, 9, 1659, 1445, 21, 1405, 11, 165, 21155, 5, 20754, 19, 1289, 7, 9, 31, 7, 4806, 58, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a049021",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
